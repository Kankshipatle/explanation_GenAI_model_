# -*- coding: utf-8 -*-
"""explanation_engine.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pl0SJo1VuYsNJcve2hjJ25K_Ft2BqGXf
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile explanation_engine.py
# 
# import torch
# from transformers import AutoTokenizer, AutoModelForCausalLM
# 
# MODEL_NAME = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
# 
# class ExplanationEngine:
#     def __init__(self):
#         self.tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
#         self.model = AutoModelForCausalLM.from_pretrained(
#             MODEL_NAME,
#             torch_dtype=torch.float32
#         )
# 
#         self.SYSTEM_PROMPT = """
# You are a supply chain explanation assistant.
# 
# Rules:
# - Explain using provided facts only
# - Do not calculate or invent values
# - Follow the format exactly
# 
# Format:
# 
# Cause:
# <text>
# 
# Recommendation:
# <text>
# 
# Justification:
# <text>
# 
# Priority:
# <High | Medium | Low>
# """
# 
#     def generate(self, facts: dict) -> str:
#         prompt = f"""{self.SYSTEM_PROMPT}
# 
# FACTS:
# {facts}
# 
# Answer:
# """
# 
#         inputs = self.tokenizer(prompt, return_tensors="pt")
# 
#         with torch.no_grad():
#             output = self.model.generate(
#                 **inputs,
#                 max_new_tokens=120,
#                 do_sample=True,
#                 temperature=0.5,
#                 top_p=0.85,
#                 repetition_penalty=1.2,
#                 eos_token_id=self.tokenizer.eos_token_id,
#                 pad_token_id=self.tokenizer.eos_token_id
#             )
# 
#         gen_tokens = output[0][inputs["input_ids"].shape[-1]:]
#         return self.tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()

from explanation_engine import ExplanationEngine

engine = ExplanationEngine()

facts = {
    "product_name": "Product B",
    "stock_gap": 10,
    "demand_change_pct": 100,
    "lead_time_days": 7,
    "risk_days": 3.5,
    "priority": "High"
}

result = engine.generate(facts)
print(result)

